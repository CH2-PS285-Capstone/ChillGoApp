{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9-ahVT1JtcW",
        "outputId": "4058ec99-a995-4045-cacd-3aae58b97fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytaNszxsJdAG",
        "outputId": "606819a5-cf34-4c13-f889-3967229743e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 2/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 3/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 4/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 5/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 6/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 7/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 8/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 9/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 10/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 11/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 12/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 13/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 14/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 15/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 16/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 17/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 18/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 19/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 20/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 21/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 22/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 23/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 24/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 25/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 26/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 27/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 28/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 29/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 30/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 31/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 32/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 33/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 34/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 35/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 36/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 37/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 38/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 39/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 40/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 41/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 42/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 43/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 44/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 45/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 46/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 47/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 48/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 49/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 50/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 51/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 52/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 53/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 54/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 55/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 56/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 57/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 58/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 59/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 60/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 61/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 62/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 63/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 64/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 65/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 66/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 67/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 68/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 69/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 70/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 71/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 72/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 73/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 74/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 75/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 76/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 77/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 78/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 79/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 80/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 81/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 82/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 83/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 84/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 85/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 86/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 87/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 88/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 89/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 90/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 91/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 92/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 93/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 94/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 95/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 96/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 97/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 98/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 99/100 - Train RMSE: 2.8382771444117587\n",
            "Epoch 100/100 - Train RMSE: 2.8382771444117587\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import joblib\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/user_rating_clean.csv')\n",
        "\n",
        "# Create a matrix of user-item ratings\n",
        "user_item_matrix = df.pivot_table(index='User_Id', columns='Place_Id', values='Place_Ratings', fill_value=0)\n",
        "\n",
        "# Normalize the ratings for collaborative filtering\n",
        "user_item_matrix_normalized = user_item_matrix.sub(user_item_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = train_test_split(df, test_size=0.2)\n",
        "\n",
        "# Create user-item matrices for training and testing sets\n",
        "train_user_item_matrix = train_data.pivot_table(index='User_Id', columns='Place_Id', values='Place_Ratings', fill_value=0)\n",
        "test_user_item_matrix = test_data.pivot_table(index='User_Id', columns='Place_Id', values='Place_Ratings', fill_value=0)\n",
        "\n",
        "# Train-test split for neural network\n",
        "train_nn, test_nn = train_test_split(user_item_matrix_normalized.values, test_size=0.2)\n",
        "\n",
        "# Function to predict ratings using cosine similarity\n",
        "def predict_ratings(user_item_matrix, similarity_matrix):\n",
        "    # Calculate the dot product of the similarity matrix and the user-item matrix\n",
        "    pred = similarity_matrix.dot(user_item_matrix)\n",
        "    pred /= np.array([np.abs(similarity_matrix).sum(axis=1)]).T\n",
        "    return pred\n",
        "\n",
        "# Function to calculate RMSE\n",
        "def rmse(prediction, actual):\n",
        "    prediction = prediction[actual.nonzero()].flatten()\n",
        "    actual = actual[actual.nonzero()].flatten()\n",
        "    return sqrt(mean_squared_error(prediction, actual))\n",
        "\n",
        "# Build a more complex Neural Network for model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu, input_dim=train_nn.shape[1]))\n",
        "model.add(tf.keras.layers.Dense(units=256, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(units=train_nn.shape[1], activation='linear'))\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model for 100 epochs\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.fit(train_nn, train_nn, epochs=1, validation_data=(test_nn, test_nn), verbose=0)\n",
        "    # Calculate user similarity using cosine similarity\n",
        "    user_similarity = cosine_similarity(train_user_item_matrix)\n",
        "\n",
        "    # Make rating predictions for travel destinations\n",
        "    user_item_prediction = predict_ratings(train_user_item_matrix.values, user_similarity)\n",
        "\n",
        "    # Calculate and print RMSE on the training data\n",
        "    train_rmse = rmse(user_item_prediction, train_user_item_matrix.values)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs} - Train RMSE: {train_rmse}')\n",
        "\n",
        "# Get the predicted ratings for all users\n",
        "all_users_ratings = pd.DataFrame(user_item_prediction, index=train_user_item_matrix.index, columns=train_user_item_matrix.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung rata-rata rating untuk setiap tempat wisata\n",
        "average_place_ratings = df.groupby('Place_Id')['Place_Ratings'].mean()\n",
        "\n",
        "# Hitung jumlah rating untuk setiap tempat wisata\n",
        "count_place_ratings = df['Place_Id'].value_counts()\n",
        "\n",
        "# Gabungkan informasi rata-rata rating dan jumlah rating ke dalam satu DataFrame\n",
        "place_info = pd.DataFrame({'Average_Rating': average_place_ratings, 'Rating_Count': count_place_ratings})\n",
        "\n",
        "# Pilih jumlah rekomendasi yang diinginkan\n",
        "top_n = 10\n",
        "\n",
        "# Pilih tempat wisata dengan rating tertinggi dan jumlah rating terbanyak\n",
        "top_recommendations = place_info.sort_values(by=['Average_Rating', 'Rating_Count'], ascending=[False, False]).head(top_n)\n",
        "\n",
        "# Tampilkan informasi tempat wisata yang direkomendasikan\n",
        "recommended_places_info = df[df['Place_Id'].isin(top_recommendations.index)][['Place_Id', 'Place_Name', 'Category', 'City']].drop_duplicates()\n",
        "recommended_places_info = recommended_places_info.set_index('Place_Id')\n",
        "recommended_places_info = recommended_places_info.loc[top_recommendations.index]\n",
        "\n",
        "print(f'\\nTop {top_n} Recommendations based on Rating and Rating Count:\\n')\n",
        "print(recommended_places_info)\n"
      ],
      "metadata": {
        "id": "gAoosMzZJ_BL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82904da-5bce-4c35-923c-973795261eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Recommendations based on Rating and Rating Count:\n",
            "\n",
            "                                  Place_Name       Category              City\n",
            "477                Curug Ciparay Tasikmalaya     Cagar Alam  Kota Tasikmalaya\n",
            "518                Taman Rekreasi Wiladatika  Taman Hiburan             Depok\n",
            "500                   CIMAHI Convention Hall         Budaya            Cimahi\n",
            "441                       Alun-alun Sumedang  Taman Hiburan          Sumedang\n",
            "493                 Cagar Budaya Pulo Majeti     Cagar Alam            Banjar\n",
            "476                   Taman Kota Tasikmalaya  Taman Hiburan  Kota Tasikmalaya\n",
            "515                Taman Herbal Insani Depok  Taman Hiburan             Depok\n",
            "449  Kampung Karuhun ECO Green Park Sumedang         Budaya          Sumedang\n",
            "517                                Godongijo     Cagar Alam             Depok\n",
            "519                          Setu Pengasinan     Cagar Alam             Depok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to an h5 file\n",
        "model.save(\"/content/drive/MyDrive/data/fitur1-2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T7BkUBLmHh8",
        "outputId": "e1798b45-be75-4b35-b017-b429d5b13f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-xdsVbjmMag"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}