# -*- coding: utf-8 -*-
"""Fitur-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ldu6jNqZKozSR8WJY7qEYjEIeIA-NZz7
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from pathlib import Path
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Membaca Data dari Dataset
destinations = pd.read_csv('/content/drive/MyDrive/data/Data_Destination_Tourism_West_java.csv', encoding = 'ISO-8859-1')
ratings = pd.read_csv('/content/drive/MyDrive/data/tourism_rating.csv')

# Jumlah data
print('Jumlah tempat wisata: ', len(destinations.Place_Id.unique()))
print('Jumlah rating: ', len(ratings.Place_Ratings))

# Konversi kolom 'Latitude' ke float64
destinations['Latitude'] = pd.to_numeric(destinations['Latitude'], errors='coerce')

# Konversi kolom 'Rating ke float64
destinations['Rating'] = pd.to_numeric(destinations['Rating'], errors = 'coerce')

# Periksa kembali informasi dataset
print(destinations.info())


destinations.head()
ratings.info()
ratings.head()
ratings.describe()

destinations = destinations.drop(['Description', 'Price', 'Rating', 'No.Telepon', 'Coordinate', 'Latitude', 'Longitude'], axis = 1)
# Pengecekan missing value destinasi wisata
destinations.isnull().sum()

# Pengecekan missing value rating pengguna
ratings.isnull().sum()

# Pengecekan data duplikan

print(f'Jumlah data destinasi wisata yang duplikat: {destinations.duplicated().sum()}')
print(f'Jumlah data rating pengguna wisata yang duplikat: {ratings.duplicated().sum()}')

# Menghapus data duplikat (Ratings)
ratings.drop_duplicates(inplace = True)

from sklearn.feature_extraction.text import TfidfVectorizer
# Mengganti '_' dengan spasi dan menghapus spasi ekstra pada kolom 'City'
destinations['City'] = destinations['City'].apply(lambda x: x.replace('_', ' ') if '_' in x else x)
destinations['City'] = destinations['City'].apply(lambda x: ' '.join(x.split()))

# Membuat objek TfidfVectorizer
tf = TfidfVectorizer()

# Melatih vektorizer dengan data 'City'
tf.fit(destinations['City'])

# Mendapatkan daftar fitur (kata) yang diekstrak dari 'City'
feature_names = tf.get_feature_names_out()

tfidf_matrix = tf.fit_transform(destinations['City'])
tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns = tf.get_feature_names_out(),
    index = destinations.Place_Name
).sample(15, axis = 0)

from sklearn.metrics.pairwise import cosine_similarity

cosine_simlrty = cosine_similarity(tfidf_matrix)
cosine_simlrty

cosine_sim_df = pd.DataFrame(
    cosine_simlrty, index=destinations['Place_Name'], columns=destinations['Place_Name'])

print('Shape: ', cosine_sim_df.shape)
cosine_sim_df.sample(20, axis = 0)

def place_recommendation(place_name, similarity_data = cosine_sim_df, items = destinations[['Place_Name', 'Category', 'City']], k =10):
  index = similarity_data.loc[:,place_name].to_numpy().argpartition(range(-1, -k, -1))
  clossest = similarity_data.columns[index[-1:-(k+2):-1]]
  clossest = clossest.drop(place_name, errors = 'ignore')
  return pd.DataFrame(clossest).merge(items).head(k)

place_name = 'Jalan Braga'
destinations[destinations.Place_Name.eq(place_name)]

place_recommendation(place_name)

# Menyimpan DataFrame ke dalam file .pickle
destinations.to_pickle('/content/drive/MyDrive/data/destinations_data.pkl')

# Menyimpan DataFrame ke dalam file .pkl
ratings.to_pickle('/content/drive/MyDrive/data/ratings_data.pkl')